{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNfromScratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYJm+RINfraZhgzAEMfPF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruv0x0x0/pclubsecytaskML/blob/main/CNNfromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYDdI8345rC_"
      },
      "outputs": [],
      "source": [
        "from matplotlib import image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from numpy import asarray\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "(X_train, Y_train), (X_test,Y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Filter Array size-nxn, conv filter nfxnxn\n",
        "class Convulation:\n",
        "    def __init__(self, nf, n):\n",
        "        self.nf = nf\n",
        "        self.n = n\n",
        "        self.filter = np.random.randn(nf, n, n)/(n*n) #will initial a normalized 3D matrix with random numbers\n",
        "\n",
        "    def patch(self, img):\n",
        "        h, w= img.shape\n",
        "        self.img = img\n",
        "        for i in range(h-self.n+1):\n",
        "          for j in range(w-self.n+1):\n",
        "            img_patch=img[i:i+self.n,j:j+self.n]\n",
        "            yield img_patch, i, j\n",
        "\n",
        "    def fwdprop(self, img):\n",
        "        h, w= img.shape  \n",
        "        Convulation_output = np.zeros((h-self.n + 1, w - self.n + 1, self.nf))\n",
        "        for img_patch, i, j in self.patch(img):\n",
        "            Convulation_output[i, j] = np.sum(img_patch*self.filter, axis=(1, 2))\n",
        "        return Convulation_output\n",
        "\n",
        "    def backprop(self, dL_dout, lrate):\n",
        "        dl_dF_params = np.zeros(self.filter.shape)\n",
        "        for img_patch, i, j in self.patch(self.img):\n",
        "            for k in range(self.n):\n",
        "                dl_dF_params[k] += img_patch*dL_dout[i, j, k]\n",
        "        self.filter -= lrate*dl_dF_params\n",
        "        return dl_dF_params    \n",
        "\"\"\"      \n",
        "conn = Convulation(18, 7)\n",
        "out = conn.fwdprop(img)\n",
        "print(out.shape)\n",
        "plt.imshow(out[:, :, 17], cmap='gray')\n",
        "plt.show()\n",
        "\"\"\"\n",
        "class Max_Pool:\n",
        "    def __init__(self, n):\n",
        "         self.n=n\n",
        "    def patch(self, img):     \n",
        "      h2= img.shape[0] // self.n\n",
        "      w2= img.shape[1] // self.n\n",
        "      self.img=img\n",
        "      \n",
        "      for i in range(h2):\n",
        "        for j in range(w2):\n",
        "          img_patch=img[(i*self.n): (i*self.n+self.n),(j*self.n): (j*self.n+self.n),]\n",
        "          yield img_patch, i, j\n",
        "\n",
        "    def fwd_prop(self,img):\n",
        "      h, w, nf=img.shape\n",
        "      output=np.zeros((h // self.n, w // self.n, nf)) \n",
        "      for img_patch,i,j in self.patch(img):\n",
        "        output[i,j]=np.amax(img_patch,axis=(0,1))\n",
        "      return output\n",
        "\n",
        "    def back_prop(self, dL_dout):\n",
        "      dL_dmax_pool=np.zeros(self.img.shape)\n",
        "      for img_patch, i, j, in self.patch(self.img):\n",
        "        h, w, nf=img_patch.shape\n",
        "        maximum_val=np.amax(img_patch,axis=(0,1))\n",
        "\n",
        "        for i1 in range(h):\n",
        "         for j1 in range(w):\n",
        "           for k1 in range(nf):\n",
        "             if img_patch[i1, j1, k1]== maximum_val[k1]:\n",
        "               dL_dmax_pool[i*self.n+i1, j*self.n+j1, k1]=dL_dout[i,j,k1]\n",
        "      return dL_dmax_pool    \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "conn2= Max_Pool(4)\n",
        "out2= conn2.fwd_prop(out)\n",
        "print(out2.shape)\n",
        "plt.imshow(out2[:, :, 17], cmap='gray')\n",
        "plt.show()  \n",
        "\"\"\"\n",
        "class Softmax:\n",
        "  def __init__(self, input_node, softmax_node):\n",
        "    self.weight=np.random.randn(input_node,softmax_node)/input_node\n",
        "    self.bias=np.zeros(softmax_node)\n",
        "\n",
        "  def forward_prop(self,image):\n",
        "    self.orig_im_shape=image.shape\n",
        "    image_modified=image.flatten()\n",
        "    self.modified_input=image_modified\n",
        "    output_val = np.dot(image_modified, self.weight) + self.bias\n",
        "    self.out=output_val\n",
        "    exp_out=np.exp(output_val)\n",
        "    return exp_out/np.sum(exp_out, axis=0)\n",
        "\n",
        "  def back_prop(self, dL_dout, learning_rate):\n",
        "    for i,grad in enumerate(dL_dout):\n",
        "      if grad==0:\n",
        "        continue\n",
        "\n",
        "      transformation_eq=np.exp(self.out)\n",
        "      S_total=np.sum(transformation_eq)\n",
        "\n",
        "      dy_dz=-transformation_eq[i]* transformation_eq/(S_total**2)\n",
        "      dy_dz[i]=transformation_eq[i]*(S_total-transformation_eq[i])/(S_total**2)\n",
        "\n",
        "      dz_dw=self.modified_input\n",
        "      dz_db=1\n",
        "      dz_d_inp=self.weight\n",
        "      dL_dz=grad*dy_dz\n",
        "      dL_dw=dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
        "      dL_db=dL_dz*dz_db\n",
        "      dL_d_inp=dz_d_inp @ dL_dz\n",
        "      self.weight-= learning_rate* dL_dw      \n",
        "      self.bias-= learning_rate* dL_db     \n",
        "\n",
        "      return dL_d_inp.reshape(self.orig_im_shape) \n",
        "class Softmax:\n",
        "  def __init__(self, input_node, softmax_node):\n",
        "    self.weight=np.random.randn(input_node,softmax_node)/input_node\n",
        "    self.bias=np.zeros(softmax_node)\n",
        "\n",
        "  def fwd_prop(self,image):\n",
        "    self.orig_im_shape=image.shape\n",
        "    image_modified=image.flatten()\n",
        "    self.modified_input=image_modified\n",
        "    output_val = np.dot(image_modified, self.weight) + self.bias\n",
        "    self.out=output_val\n",
        "    exp_out=np.exp(output_val)\n",
        "    return exp_out/np.sum(exp_out, axis=0)\n",
        "\n",
        "  def back_prop(self, dL_dout, learning_rate):\n",
        "    for i,grad in enumerate(dL_dout):\n",
        "      if grad==0:\n",
        "        continue\n",
        "\n",
        "      transformation_eq=np.exp(self.out)\n",
        "      S_total=np.sum(transformation_eq)\n",
        "\n",
        "      dy_dz=-transformation_eq[i]* transformation_eq/(S_total**2)\n",
        "      dy_dz[i]=transformation_eq[i]*(S_total-transformation_eq[i])/(S_total**2)\n",
        "\n",
        "      dz_dw=self.modified_input\n",
        "      dz_db=1\n",
        "      dz_d_inp=self.weight\n",
        "      dL_dz=grad*dy_dz\n",
        "      dL_dw=dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
        "      dL_db=dL_dz*dz_db\n",
        "      dL_d_inp=dz_d_inp @ dL_dz\n",
        "      self.weight-= learning_rate* dL_dw      \n",
        "      self.bias-= learning_rate* dL_db     \n",
        "\n",
        "      return dL_d_inp.reshape(self.orig_im_shape) \n",
        "\n",
        "conn3=Softmax(18*393*268, 10)\n",
        "out3=conn3.fwd_prop(out2)\n",
        "print(out3)\n",
        "x=6900\n",
        "train_images= X_train[:x]\n",
        "train_labels= Y_train[:x]\n",
        "test_images= X_test[:x]\n",
        "test_labels= Y_test[:x]\n",
        "conv=Convulation(8,3)\n",
        "pool=Max_Pool(2)\n",
        "softmax=Softmax(13*13*8,10)\n",
        "\n",
        "def cnn_forward_prop(image, label):\n",
        "  out_p= conv.fwdprop((image/255)-0.5)\n",
        "  out_p= pool.fwd_prop(out_p)\n",
        "  out_p=softmax.fwd_prop(out_p)\n",
        "  cross_ent_loss=-np.log(out_p[label]) if out_p[label]>0 else 0\n",
        "  accuracy_eval=1 if np.argmax(out_p) == label else 0\n",
        "  return out_p, cross_ent_loss, accuracy_eval\n",
        "\n",
        "def training_cnn(image, label, learn_rate=0.005):\n",
        "  out, loss, acc= cnn_forward_prop(image,label) \n",
        "  gradient= np.zeros(10)\n",
        "  gradient[label]=-1/out[label]\n",
        "\n",
        "  grad_back=softmax.back_prop(gradient, learn_rate)\n",
        "  grad_back= pool.back_prop(grad_back)\n",
        "  grad_back= conv.backprop(grad_back,learn_rate)\n",
        "\n",
        "  return loss, acc  \n",
        "for epoch1 in range(4):\n",
        "  print('Epoch %d ---->' % (epoch1+1))\n",
        "\n",
        "  shuffle_data=np.random.permutation(len(train_images))\n",
        "  train_images=train_images[shuffle_data]\n",
        "  train_labels=train_labels[shuffle_data]\n",
        "\n",
        "  loss=0\n",
        "  num_correct=0\n",
        "  for i, (im,label) in enumerate(zip(train_images,train_labels)):\n",
        "    if i % 100 ==0:\n",
        "    \n",
        "      print('step')\n",
        "      print((i+1)/100)\n",
        "      print('avg loss: ')\n",
        "      print(loss/100)\n",
        "      print('accuracy')\n",
        "      print(num_correct)\n",
        "      print('\\n')\n",
        "      loss=0\n",
        "      num_correct=0\n",
        "    l1,accu=training_cnn(im, label)\n",
        "    loss+=l1\n",
        "    num_correct+=accu\n",
        "print('*TestingPhase*')\n",
        "loss=0\n",
        "num_correct=0\n",
        "for im,label in zip(test_images,test_labels):\n",
        "  _, l1, accu=cnn_forward_prop(im, label)\n",
        "  loss+=l1\n",
        "  num_correct+=accu\n",
        "num_tests=len(test_images)\n",
        "\n",
        "print('Loss:', loss/num_tests) \n",
        "print('Accuracy:',num_correct/num_tests)\n",
        "\n",
        "\n",
        "y=69\n",
        "plt.imshow(train_images[y], cmap='gray')\n",
        "plt.show()\n",
        "print(train_images[y].shape)\n",
        "out_p= conv.fwdprop((train_images[y]/255)-0.5)\n",
        "out_p= pool.fwd_prop(out_p)\n",
        "out_p=softmax.fwd_prop(out_p)\n",
        "print(\"image is probably\",np.argmax(out_p))\n",
        "\"\"\"\n",
        "img = cv2.imread('/content/sample_data/5.png', cv2.IMREAD_GRAYSCALE)/255\n",
        "def predict(img1):\n",
        "  img = cv2.resize(img1, (28, 28))\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.show()\n",
        "  print(img.shape)\n",
        "  out_p= conv.fwdprop((img/255)-0.5)\n",
        "  out_p= pool.fwd_prop(out_p)\n",
        "  out_p=softmax.fwd_prop(out_p)\n",
        "  print(\"image is probably\",np.argmax(out_p))\n",
        "predict(img)\n",
        "\"\"\""
      ]
    }
  ]
}